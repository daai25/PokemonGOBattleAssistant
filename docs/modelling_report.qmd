# Modelling Report
Summarization of details of the modelling activities.

## Initial situation
Our aim of the modellng is to be able to accurately predict who the winner of a pokemon battle is when given two pokemon.
The data set used is the (pokemon_data.csv) 
Our independant variables are all of the stats for the pokemon (type, moves, attack, defence, etc.), and our dependant variable is the 'win' variable.
We created several models, including Logistic Regression, Random Forest, and Gradient Boosting. For our final product, we will be using the Gradient Boosting Model.

- Aim of the modelling - consistent with *Data Mining Goals* in the project charta
- Data set(s) and/or feature set used (references to the data report)
- Description of the independent variables and (if applicable) the target variable
- Type of model used or developed

## Model Descriptions
Overview of the models used and/or implemented and their configurations 
- Detailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.)
- Graphical representation of the modelling pipeline
- If applicable: link to the code of the modelling pipeline, version information in code repository, configuration files
- If possible, links to the artefacts of the executed modelling pipeline (training experiment)
- Link to the literature in which the model/method is described
- Hyperparameters

### Logistic Regression Model

**Model Explanation:** The logistic regression model works by predicting the probability of a binary outcome by applying a sigmoid function to a weighted sum of input features.

**Application:** As an initial baseline, logistic regression was trained alongside our ensemble models. While computationally efficient and straightforward to interpret, it plateaued at ~50% accuracy—no better than random guessing—so we discontinued its development early.

### Random Forest Model

**Model Explanation:** The random forest model works by making predictions by combining the results of many decision trees, each trained on random subsets of the data and features, which improves accuracy and reduces overfitting.

**Application:** After hyperparameter tuning via grid search, the random forest classifier achieved ~69% validation accuracy. Although competitive with gradient boosting’s ~72%, its treatment of categorical Pokémon type features proved slightly less effective, leading us to concentrate further efforts on boosting methods.

### Gradient Boosting Model

**Model Explanation:** The gradient boosting model is an ensemble technique that builds decision trees sequentially, where each new tree is trained to correct the errors (residuals) of the previous ensemble. It optimizes a loss function via gradient descent in function space, reducing bias and improving predictive performance.

**Application:** Leveraging iterative feature engineering—such as stat ratio features—the gradient boosting model’s performance climbed to ~75% accuracy. However, feature‐importance analysis revealed underweighting of categorical type attributes, motivating a search for a model with stronger native categorical support.

::: {.catboost-highlight}
<div class="chosen-model">Chosen Model</div>

### Category Boosting Model (CatBoost)

**Model Explanation:** The CatBoost model is a gradient boosting algorithm designed for handling categorical features natively. It uses ordered boosting and symmetrical trees to reduce overfitting, automatically encodes categorical variables, and often achieves high accuracy with minimal preprocessing.

**Application:** By adopting CatBoost, which natively encodes categorical variables, we immediately saw validation accuracy jump to ~78%. With additional fine-tuning of iterations, learning rate, and tree depth, performance rose to ~79%. Feature importance plots confirmed that Pokémon types were now appropriately prioritized, solidifying CatBoost as our final production model.
:::


## Results
Key figures dependent on the model and modelling objective

- RMSD, ROC/Lift-Charts, AUC, Confusion Matrix, Accuracy, Precision, Recall
- Coherence, Perplexity, ... 
- If applicable: analyses/plots of (hyper)parameter screenings

## Model Interpretation
- If applicable: Results from the application of "explanatory models"
- Were the modelling objectives achieved?
- The findings resulting from the modelling phase: can the project objective be achieved with the results from the modelling phase?
- How can the findings be used? Are there any limitations?

## Conclusions and next steps
- Conclusions of the key findings from the modelling phase
- Discussion about limitations
- Proposal for extensions and further work
- Proposal for the deployment of the generated insights/model
