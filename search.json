[
  {
    "objectID": "project_charta.html",
    "href": "project_charta.html",
    "title": "Project Charta",
    "section": "",
    "text": "New players coming to Pokemon Go are going to struggle with the highly complex combat system. There is much to consider such as type weaknesses, charged moves, fast moves, pokemon stats, and more.\nAnother problem that new players will have is identifying the many different pokemon and learning their names. Given that there are over 800 pokemon in pokemon go, it’ll be no easy task.\n\n\n\nWe are developing a Pokémon battle assistant that recommends the best Pokemon choices for players during battles. Additionally, we are creating an image recognition model that identifies Pokémon based on images and outputs their names.\nWe will use Python libraries such as pandas, selenium, and csv for data processing and automation. Our data source and battle simulations will rely entirely on pvpoke.com. ChatGPT will assist us with coding and other support tasks. As for models we will use the following models Linear Regression, Random Forest, Gradient Boosing, and Categorical Boost (CatBoost).\n\n\n\nThe project must be completed within 4 weeks, requiring careful planning and time management.\nThe team size is limited to four members\nComplete dependency on pvpoke.com for battle data and simulations; potential risk if the site changes or becomes unavailable.\nThe image recognition model’s accuracy depends on the quality and quantity of training data.\n\n\n\n\n\nPotential changes in pvpoke.com’s site structure or access policies could disrupt data gathering and simulations.\nInsufficient training data or poor labeling could reduce image recognition model performance.\nIntegration challenges between the battle assistant and the image recognition model or difficulties with Python libraries.\nThe tight 4-week timeline may limit thorough testing, optimization, and documentation.\nRisk of scope creep if project goals are not clearly defined and managed.\n\n\n\n\n\nFor our battle assistant to be successful it needs to boost the winrate for new players overall while utilizing multiple aspects for pokemon fights.\nFor our image recognition to be successful it should be able to recognize a pokemon and output the correct name with a high accuracy rate.\n\n\n\n\n\n\nInput Data: Battle simulation dataset (data_acquisition/vectorized_data/battle_data_numeric.csv)\nTask: Binary classification to predict which Pokémon wins (left vs. right)\nTarget Variable: winner (1 = left wins, 0 = right wins)\nMetrics and Targets:\n\nAccuracy ≥ 0.79\nF1-score ≥ 0.78\n\nGoal: Provide reliable win‐probabilities to inform user decisions in real-time.\n\n\n\n\n\nInput Data: Pokémon image dataset (data_acquisition/image_dataset/final_pokemon_dataset)\nTask: Multi-class classification to identify Pokémon species (727 classes)\nTarget Variable: pokemon_name\nMetrics and Targets:\n\nTop-1 Accuracy ≥ 0.90\nPrecision & Recall ≥ 0.88\n\nGoal: Enable seamless user input via image upload with high confidence.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Project Plan\n\n\n\n\n\n\n\n\nRoles:\n\nBattle Simulator Architect\n\nGradient Boosting & CatBoost Model Developer\n\nWeb App Contributor\n\nTasks:\n\nDesigned and implemented the 1v1 battle simulation engine\n\nDeveloped and tuned Gradient Boosting and CatBoost models for battle prediction\n\nAssisted with building and integrating the Streamlit web interface\n\nContact Info:\n\nEmail: Boermaca@mail.gvsu.edu\nGithub: https://github.com/Calebb2202\n\n\n\n\nRoles:\n\nBattle Simulator Contributor\n\nLinear Regression Model Developer\n\nWeb App Engineer\n\nTasks:\n\nAssisted in creating the battle simulation framework\n\nImplemented the Linear Regression baseline model for battle outcome prediction\n\nBuilt and deployed the final Streamlit web app application\n\nContact Info:\n\nEmail: dejondie@mail.gvsu.edu\nGithub: https://github.com/Dasnapplel\n\n\n\n\nRoles:\n\nImage Pipeline Engineer\n\nDeep Learning Model Developer\n\nTasks:\n\nScraped and cleaned image data for the deep learning pipeline\n\nDeveloped and trained CFAR, CNN, and transfer-learning models for Pokémon classification\n\nContact Info:\n\nEmail: baumadyl@students.zhaw.ch\nGithub: https://github.com/baumadyl01\n\n\n\n\nRoles:\n\nData Acquisition Specialist\n\nRandom Forest Model Developer\n\nDeep Learning Model Collaborator\n\nTasks:\n\nScraped initial Pokémon stats, moves, and types; performed vectorization\n\nImplemented the Random Forest classifier for battle prediction\n\nContributed to the deep learning image classification project\n\nContact Info:\n\nEmail: vangsmax@students.zhaw.ch\nGithub: https://github.com/vangmax",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#problem-definition",
    "href": "project_charta.html#problem-definition",
    "title": "Project Charta",
    "section": "",
    "text": "New players coming to Pokemon Go are going to struggle with the highly complex combat system. There is much to consider such as type weaknesses, charged moves, fast moves, pokemon stats, and more.\nAnother problem that new players will have is identifying the many different pokemon and learning their names. Given that there are over 800 pokemon in pokemon go, it’ll be no easy task.",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#situation-assessment",
    "href": "project_charta.html#situation-assessment",
    "title": "Project Charta",
    "section": "",
    "text": "We are developing a Pokémon battle assistant that recommends the best Pokemon choices for players during battles. Additionally, we are creating an image recognition model that identifies Pokémon based on images and outputs their names.\nWe will use Python libraries such as pandas, selenium, and csv for data processing and automation. Our data source and battle simulations will rely entirely on pvpoke.com. ChatGPT will assist us with coding and other support tasks. As for models we will use the following models Linear Regression, Random Forest, Gradient Boosing, and Categorical Boost (CatBoost).\n\n\n\nThe project must be completed within 4 weeks, requiring careful planning and time management.\nThe team size is limited to four members\nComplete dependency on pvpoke.com for battle data and simulations; potential risk if the site changes or becomes unavailable.\nThe image recognition model’s accuracy depends on the quality and quantity of training data.\n\n\n\n\n\nPotential changes in pvpoke.com’s site structure or access policies could disrupt data gathering and simulations.\nInsufficient training data or poor labeling could reduce image recognition model performance.\nIntegration challenges between the battle assistant and the image recognition model or difficulties with Python libraries.\nThe tight 4-week timeline may limit thorough testing, optimization, and documentation.\nRisk of scope creep if project goals are not clearly defined and managed.",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#project-goals-and-success-criteria",
    "href": "project_charta.html#project-goals-and-success-criteria",
    "title": "Project Charta",
    "section": "",
    "text": "For our battle assistant to be successful it needs to boost the winrate for new players overall while utilizing multiple aspects for pokemon fights.\nFor our image recognition to be successful it should be able to recognize a pokemon and output the correct name with a high accuracy rate.",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#data-mining-goals",
    "href": "project_charta.html#data-mining-goals",
    "title": "Project Charta",
    "section": "",
    "text": "Input Data: Battle simulation dataset (data_acquisition/vectorized_data/battle_data_numeric.csv)\nTask: Binary classification to predict which Pokémon wins (left vs. right)\nTarget Variable: winner (1 = left wins, 0 = right wins)\nMetrics and Targets:\n\nAccuracy ≥ 0.79\nF1-score ≥ 0.78\n\nGoal: Provide reliable win‐probabilities to inform user decisions in real-time.\n\n\n\n\n\nInput Data: Pokémon image dataset (data_acquisition/image_dataset/final_pokemon_dataset)\nTask: Multi-class classification to identify Pokémon species (727 classes)\nTarget Variable: pokemon_name\nMetrics and Targets:\n\nTop-1 Accuracy ≥ 0.90\nPrecision & Recall ≥ 0.88\n\nGoal: Enable seamless user input via image upload with high confidence.",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#project-plan",
    "href": "project_charta.html#project-plan",
    "title": "Project Charta",
    "section": "",
    "text": "Figure 1: Project Plan",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "project_charta.html#roles-and-contact-details",
    "href": "project_charta.html#roles-and-contact-details",
    "title": "Project Charta",
    "section": "",
    "text": "Roles:\n\nBattle Simulator Architect\n\nGradient Boosting & CatBoost Model Developer\n\nWeb App Contributor\n\nTasks:\n\nDesigned and implemented the 1v1 battle simulation engine\n\nDeveloped and tuned Gradient Boosting and CatBoost models for battle prediction\n\nAssisted with building and integrating the Streamlit web interface\n\nContact Info:\n\nEmail: Boermaca@mail.gvsu.edu\nGithub: https://github.com/Calebb2202\n\n\n\n\nRoles:\n\nBattle Simulator Contributor\n\nLinear Regression Model Developer\n\nWeb App Engineer\n\nTasks:\n\nAssisted in creating the battle simulation framework\n\nImplemented the Linear Regression baseline model for battle outcome prediction\n\nBuilt and deployed the final Streamlit web app application\n\nContact Info:\n\nEmail: dejondie@mail.gvsu.edu\nGithub: https://github.com/Dasnapplel\n\n\n\n\nRoles:\n\nImage Pipeline Engineer\n\nDeep Learning Model Developer\n\nTasks:\n\nScraped and cleaned image data for the deep learning pipeline\n\nDeveloped and trained CFAR, CNN, and transfer-learning models for Pokémon classification\n\nContact Info:\n\nEmail: baumadyl@students.zhaw.ch\nGithub: https://github.com/baumadyl01\n\n\n\n\nRoles:\n\nData Acquisition Specialist\n\nRandom Forest Model Developer\n\nDeep Learning Model Collaborator\n\nTasks:\n\nScraped initial Pokémon stats, moves, and types; performed vectorization\n\nImplemented the Random Forest classifier for battle prediction\n\nContributed to the deep learning image classification project\n\nContact Info:\n\nEmail: vangsmax@students.zhaw.ch\nGithub: https://github.com/vangmax",
    "crumbs": [
      "Project Charta"
    ]
  },
  {
    "objectID": "md-templates/project_charta_template.html",
    "href": "md-templates/project_charta_template.html",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Formulate the problem and important information about the domain and/or business area in which the product is to be developed: What exactly is the problem and the expected benefit of the project? Why should we undertake this effort?\nThis includes a summary of the most important findings from the user analysis: relevant segments and user groups. Describe the problems and needs of the users of the product to be developed.\nStakeholders: List the people involved in and affected by the project. Describe their goals and relationships with each other. Visualisation in the form of a stakeholder map can provide a quick overview.\nYou can reference more detailed analyses such as individual “personas” or interviews in separate documents in the appendix.\n\n\n\nDescribe the available resources (personnel, material, (software) tools, infrastructure, etc.) and time as well as restrictions and constraints. Possible risks that may arise during the project are also identified.\n\n\n\nWhen is the project successful from a client/stakeholder perspective: Formulate (qualitative) objectives, wherever possible, corresponding key metrics and the target values to be achieved within the project.\nIt is also often helpful to specify what is explicitly excluded from the project objectives (out of scope).\n\n\n\nMap the problem definition, datasets to be used and primary objective onto a data mining task, e.g.:\n\nClassification\nRegression\nClustering\nOutlier Detection\nAssociation rule learning (market basket analysis)\nRecommender System\nVisualisation\n…\n\nAlong with the definition of the actual technical problem (category) to be solved, the project goals must be mapped onto quitable quantitative metrics and corresponding target values. For example, for a classification task one might specify an F-score of 0.9 as a minimal requirement for an acceptable solution.\nSuch a requirement should be aligned with the overall project goals and/or literature references or justified by other references, respectively.\n\n\n\nDivide the project into individual phases, describe them briefly and draw up a preliminary timetable, e.g. as a Gantt chart:\ngantt\n    title A Gantt Diagram\n    dateFormat YYYY-MM-DD\n    tickInterval 5day\n    section Project Understanding\n        Define problem,     :a1, 2024-07-01, 1d\n        Determine project goals     :a2, 2024-07-01, 1d\n        List available resources     :a3, 2024-07-02, 1d\n        Set data mining goals    :a4, 2024-07-03, 1d\n        Create project plan    :a5, 2024-07-03, 1d\n        Project checkpoint: milestone, m1, 2024-07-04, 4m\n    section Data Acquisition and Exploration\n        Acquire data :a6, 2024-07-02, 2d\n        Exploratory data analysis   :a7, 2024-07-03, 2d\n        \n    section Modelling\n        Create initial model   :a8, 2024-07-09, 1d\n        Additional feature engineering :a9, 2024-07-10, 1d\n        Prepare modelling report :a10, 2024-07-10, 2h\n    section Evaluation\n        Prepare presentation :a10, 2024-07-10, 2h\n        Project presentation : milestone, m2, 2024-07-11, 4m\nSee Mermaid syntax for Gantt charts.\n\n\n\nList the people involved in the development work here with their role titles, tasks and contact details"
  },
  {
    "objectID": "md-templates/project_charta_template.html#problem-definition",
    "href": "md-templates/project_charta_template.html#problem-definition",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Formulate the problem and important information about the domain and/or business area in which the product is to be developed: What exactly is the problem and the expected benefit of the project? Why should we undertake this effort?\nThis includes a summary of the most important findings from the user analysis: relevant segments and user groups. Describe the problems and needs of the users of the product to be developed.\nStakeholders: List the people involved in and affected by the project. Describe their goals and relationships with each other. Visualisation in the form of a stakeholder map can provide a quick overview.\nYou can reference more detailed analyses such as individual “personas” or interviews in separate documents in the appendix."
  },
  {
    "objectID": "md-templates/project_charta_template.html#situation-assessment",
    "href": "md-templates/project_charta_template.html#situation-assessment",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Describe the available resources (personnel, material, (software) tools, infrastructure, etc.) and time as well as restrictions and constraints. Possible risks that may arise during the project are also identified."
  },
  {
    "objectID": "md-templates/project_charta_template.html#project-goals-and-success-criteria",
    "href": "md-templates/project_charta_template.html#project-goals-and-success-criteria",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "When is the project successful from a client/stakeholder perspective: Formulate (qualitative) objectives, wherever possible, corresponding key metrics and the target values to be achieved within the project.\nIt is also often helpful to specify what is explicitly excluded from the project objectives (out of scope)."
  },
  {
    "objectID": "md-templates/project_charta_template.html#data-mining-goals",
    "href": "md-templates/project_charta_template.html#data-mining-goals",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Map the problem definition, datasets to be used and primary objective onto a data mining task, e.g.:\n\nClassification\nRegression\nClustering\nOutlier Detection\nAssociation rule learning (market basket analysis)\nRecommender System\nVisualisation\n…\n\nAlong with the definition of the actual technical problem (category) to be solved, the project goals must be mapped onto quitable quantitative metrics and corresponding target values. For example, for a classification task one might specify an F-score of 0.9 as a minimal requirement for an acceptable solution.\nSuch a requirement should be aligned with the overall project goals and/or literature references or justified by other references, respectively."
  },
  {
    "objectID": "md-templates/project_charta_template.html#project-plan",
    "href": "md-templates/project_charta_template.html#project-plan",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "Divide the project into individual phases, describe them briefly and draw up a preliminary timetable, e.g. as a Gantt chart:\ngantt\n    title A Gantt Diagram\n    dateFormat YYYY-MM-DD\n    tickInterval 5day\n    section Project Understanding\n        Define problem,     :a1, 2024-07-01, 1d\n        Determine project goals     :a2, 2024-07-01, 1d\n        List available resources     :a3, 2024-07-02, 1d\n        Set data mining goals    :a4, 2024-07-03, 1d\n        Create project plan    :a5, 2024-07-03, 1d\n        Project checkpoint: milestone, m1, 2024-07-04, 4m\n    section Data Acquisition and Exploration\n        Acquire data :a6, 2024-07-02, 2d\n        Exploratory data analysis   :a7, 2024-07-03, 2d\n        \n    section Modelling\n        Create initial model   :a8, 2024-07-09, 1d\n        Additional feature engineering :a9, 2024-07-10, 1d\n        Prepare modelling report :a10, 2024-07-10, 2h\n    section Evaluation\n        Prepare presentation :a10, 2024-07-10, 2h\n        Project presentation : milestone, m2, 2024-07-11, 4m\nSee Mermaid syntax for Gantt charts."
  },
  {
    "objectID": "md-templates/project_charta_template.html#roles-and-contact-details",
    "href": "md-templates/project_charta_template.html#roles-and-contact-details",
    "title": "Sample Project - Project Charta",
    "section": "",
    "text": "List the people involved in the development work here with their role titles, tasks and contact details"
  },
  {
    "objectID": "md-templates/evaluation_decision_log.html",
    "href": "md-templates/evaluation_decision_log.html",
    "title": "Sample Project - Decision Log",
    "section": "",
    "text": "Sample Project - Decision Log\nThis protocol summarises the decisions from the evaluation of the data mining phase, which are made, for example, in a workshop together with the client and other stakeholders.\nDecide:\n\nDo results meet user needs?\nContinuation of the project yes/no\nPlanning of the deployment\nCarry out an additional data mining iteration\n\nAcquire more or different data\nImprovements in the modelling\nAddress governance issues\nor ethical considerations\n…\n\n\nAny presentation material created for such a workshop should also be stored in the docs folder.\nIt is important to list who was involved in the decisions and when they were made.\nThe structure and level of detail of this protocol should be tailored to the customs of the relevant organisation and the requirements of the decision-makers. It might include already a high level description of the envisioned product to be deployed."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pokemon GO Battle Assistant",
    "section": "",
    "text": "The Pokemon GO Battle Assistant is an advanced prediction system that uses machine learning to help trainers make strategic decisions in Pokemon GO battles. By analyzing Pokemon statistics, battle mechanics, and historical performance data, our system predicts battle outcomes with high accuracy and provides recommendations for optimal team composition.\nOur system currently supports 727 Pokémon species, covering the vast majority of creatures available in Pokémon GO.",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Pokemon GO Battle Assistant",
    "section": "",
    "text": "The Pokemon GO Battle Assistant is an advanced prediction system that uses machine learning to help trainers make strategic decisions in Pokemon GO battles. By analyzing Pokemon statistics, battle mechanics, and historical performance data, our system predicts battle outcomes with high accuracy and provides recommendations for optimal team composition.\nOur system currently supports 727 Pokémon species, covering the vast majority of creatures available in Pokémon GO.",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "Pokemon GO Battle Assistant",
    "section": "Key Features",
    "text": "Key Features\n\nBattle Outcome Prediction: Predicts the winner of 1v1 Pokemon battles using machine learning models\nPokemon Image Recognition: Identifies Pokemon from images using Deep Learning computer vision models\nType & Move Analysis: Evaluates effectiveness of different Pokemon types in battle\nData-Driven Insights: Uses data from thousands of simulated battles for training",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#data-sources",
    "href": "index.html#data-sources",
    "title": "Pokemon GO Battle Assistant",
    "section": "Data Sources",
    "text": "Data Sources\nOur system utilizes three primary data sources:\n\nPokemon Statistics & Rankings: Comprehensive dataset of Pokemon attributes from PvPoke rankings site\nBattle Simulation Data: 20,000 simulated battle outcomes with detailed performance metrics from PvPoke battles site\nPokemon Image Dataset: Collection of Pokemon images retrieved via DuckDuckGo Search API for training the image recognition model",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#machine-learning-approach",
    "href": "index.html#machine-learning-approach",
    "title": "Pokemon GO Battle Assistant",
    "section": "Machine Learning Approach",
    "text": "Machine Learning Approach\nOur system evaluates multiple machine learning models to find the optimal solution for battle prediction:\n\nLogistic Regression: A baseline model for binary classification\nRandom Forest Classifier: An ensemble method that builds multiple decision trees\nGradient Boosting: Advanced ensemble technique that builds trees sequentially\nCatBoost: An ensemble method optimized for handling categorical features\n\nAfter rigorous evaluation and cross-validation, the best performing model is the CatBoost model, and is selected for deployment. The selected model learns complex patterns in:\n\nPokemon type effectiveness relationships\nStat advantages/disadvantages\nMove selection\nOverall battle performance\n\nFor detailed information about our machine learning approach, see the Modelling Report.",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#deep-learning-approach",
    "href": "index.html#deep-learning-approach",
    "title": "Pokemon GO Battle Assistant",
    "section": "Deep Learning Approach",
    "text": "Deep Learning Approach\nThe image recognition component of our system employs deep learning techniques to identify Pokemon from photos:\n\nCFAR Model: A lightweight convolutional neural network for basic image classification\nCustom CNN: Advanced architecture with batch normalization and regularization techniques\nTransfer Learning: EfficientNetB0 pre-trained model adapted for Pokemon recognition\n\nOur iterative approach explored multiple architectures to balance accuracy and computational requirements, with each model offering different trade-offs in performance and resource usage.\nFor comprehensive details about our deep learning implementations, see the Deep Learning Report.",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "index.html#project-documentation",
    "href": "index.html#project-documentation",
    "title": "Pokemon GO Battle Assistant",
    "section": "Project Documentation",
    "text": "Project Documentation\nThis documentation provides comprehensive details on:\n\nData Collection & Processing\nModelling Approach & Results\nDeep Learning Implementation\nEvaluation Metrics & Performance\nProject Development Process",
    "crumbs": [
      "Pokemon GO Battle Assistant"
    ]
  },
  {
    "objectID": "deeplearning_report.html",
    "href": "deeplearning_report.html",
    "title": "Deep Learning Report",
    "section": "",
    "text": "This report summarizes the details of the deep learning activities for Pokémon image classification.\n\n\nOur aim for the deep learning component is to accurately identify Pokémon from images, which complements the battle prediction system. This visual recognition capability allows users to upload images of Pokémon they encounter and get immediate battle strategy recommendations.\nThe dataset used consists of Pokémon images collected from various sources and organized into a structured format in the data_acquisition/image_dataset/final_pokemon_dataset directory, with separate train and test folders.\nOur independent variables are the pixel values of the Pokémon images, and our dependent variable is the Pokémon species label. We created three different deep learning models: a CFAR (Convolutional Filter and Response) model, a custom CNN (Convolutional Neural Network), and a pre-trained transfer learning model using EfficientNetB0.\n\nAim of the modeling: Create an accurate image classifier that can identify Pokémon species from images\nDataset used: Collection of Pokémon images organized by species in the final_pokemon_dataset folder\nIndependent variables: Image pixel values (RGB channels)\nTarget variable: Pokémon species name\nTypes of models used: CFAR, CNN, and pre-trained EfficientNetB0\n\n\n\n\nThis section provides an overview of the three deep learning models implemented for Pokémon image classification.\n\n\nThe CFAR (Convolutional Filter and Response) model is a lightweight convolutional neural network designed for basic Pokémon image classification.\n\nImplementation details:\n\nLibrary: TensorFlow/Keras\nInput shape: 64x64x3 (RGB images)\nArchitecture:\n\n3 convolutional layers (32, 64, and 128 filters)\n3 max pooling layers\n1 dense hidden layer (256 neurons)\nOutput layer with softmax activation\n\nOptimizer: Adam\nLoss function: Categorical cross-entropy\nTraining: 30 epochs with validation after each epoch\n\nModeling pipeline:\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[64x64x3 RGB Image]\n    end\n    \n    subgraph conv1 [Layer 1]\n    C1[Conv2D 32 Filters] --&gt; MP1[MaxPooling]\n    end\n    \n    subgraph conv2 [Layer 2]\n    C2[Conv2D 64 Filters] --&gt; MP2[MaxPooling]\n    end\n    \n    subgraph conv3 [Layer 3]\n    C3[Conv2D 128 Filters] --&gt; MP3[MaxPooling]\n    end\n    \n    subgraph dense [Dense Layers]\n    F[Flatten] --&gt; D1[Dense 256 neurons]\n    D1 --&gt; Out[Output Layer]\n    end\n    \n    I --&gt; C1\n    MP1 --&gt; C2\n    MP2 --&gt; C3\n    MP3 --&gt; F\n    \n    style input fill:#e1f5fe\n    style conv1 fill:#ffecb3\n    style conv2 fill:#ffecb3\n    style conv3 fill:#ffecb3\n    style dense fill:#e8f5e9\n\n\n\n\n\n\nThe diagram above illustrates the architecture of the CFAR model. Starting with an input RGB image (64x64x3), the data flows through three convolutional layers with increasing filter sizes (32, 64, and 128), each followed by a MaxPooling operation to reduce dimensionality. The feature maps from the final convolutional layer are flattened and passed through a dense layer with 256 neurons, which connects to the output layer for classification. This sequential structure enables the model to progressively extract and refine features from the input images before making the final classification decision.\n\nCode link: deployment/image_classification/cfar/train_pokemon_classifier_cfar.py\nHyperparameters:\n\nLearning rate: Default for Adam optimizer\nBatch size: 32\nImage size: 64x64 pixels\nNo data augmentation\n\n\n\n\n\nThe CNN model is a more advanced deep learning architecture with multiple convolutional layers designed for improved feature extraction and classification accuracy.\n\nImplementation details:\n\nLibrary: TensorFlow/Keras\nInput shape: 64x64x3 (RGB images)\nArchitecture:\n\n4 convolutional layers with batch normalization and dropout\nEach layer has double convolution layers with increasing filter sizes (32→64→128→256)\nMax pooling after each layer\nFlatten layer followed by dense layer (512 neurons)\nOutput layer with softmax activation\n\nOptimizer: Adam with configurable learning rate\nLoss function: Categorical cross-entropy\nTraining: Up to 80 epochs with early stopping and learning rate reduction\n\nModeling pipeline:\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[64x64x3 RGB Image]\n    end\n    \n    subgraph aug [Data Augmentation]\n    A1[Random Rotation] --&gt; A2[Width/Height Shifts]\n    A2 --&gt; A3[Shear Transform]\n    A3 --&gt; A4[Zoom]\n    A4 --&gt; A5[Horizontal Flip]\n    end\n    \n    subgraph conv1 [Layer 1]\n    C1A[Conv2D 32] --&gt; BN1A[BatchNorm]\n    BN1A --&gt; C1B[Conv2D 32] \n    C1B --&gt; BN1B[BatchNorm]\n    BN1B --&gt; MP1[MaxPooling]\n    MP1 --&gt; D1[Dropout 0.25]\n    end\n    \n    subgraph conv2 [Layer 2]\n    C2A[Conv2D 64] --&gt; BN2A[BatchNorm]\n    BN2A --&gt; C2B[Conv2D 64] \n    C2B --&gt; BN2B[BatchNorm]\n    BN2B --&gt; MP2[MaxPooling]\n    MP2 --&gt; D2[Dropout 0.25]\n    end\n    \n    subgraph conv3 [Layer 3]\n    C3A[Conv2D 128] --&gt; BN3A[BatchNorm]\n    BN3A --&gt; C3B[Conv2D 128] \n    C3B --&gt; BN3B[BatchNorm]\n    BN3B --&gt; MP3[MaxPooling]\n    MP3 --&gt; D3[Dropout 0.25]\n    end\n    \n    subgraph conv4 [Layer 4]\n    C4A[Conv2D 256] --&gt; BN4A[BatchNorm]\n    BN4A --&gt; C4B[Conv2D 256] \n    C4B --&gt; BN4B[BatchNorm]\n    BN4B --&gt; MP4[MaxPooling]\n    MP4 --&gt; D4[Dropout 0.25]\n    end\n    \n    subgraph dense [Dense Layers]\n    F[Flatten] --&gt; DL1[Dense 512]\n    DL1 --&gt; BN5[BatchNorm]\n    BN5 --&gt; D5[Dropout 0.5]\n    D5 --&gt; Out[Output Layer]\n    end\n    \n    I --&gt; A1\n    A5 --&gt; C1A\n    D1 --&gt; C2A\n    D2 --&gt; C3A\n    D3 --&gt; C4A\n    D4 --&gt; F\n    \n    style input fill:#e1f5fe\n    style aug fill:#e8f5e9\n    style conv1 fill:#ffecb3\n    style conv2 fill:#ffe082\n    style conv3 fill:#ffd54f\n    style conv4 fill:#ffca28\n    style dense fill:#e8f5e9\n\n\n\n\n\n\nThe diagram above illustrates the more complex CNN architecture used for Pokémon classification. This model features four convolutional layers with progressively increasing filter sizes (32→64→128→256), each implementing a double convolution pattern. The pipeline begins with data augmentation techniques (rotation, shifts, shear, zoom, and flipping) that enhance the training dataset and improve generalization. Every layer follows the same structure: two convolutional layers, each followed by batch normalization, then max pooling, and finally dropout (0.25) to prevent overfitting. After the convolutional layers, the data is flattened and passed through a dense layer with 512 neurons, followed by batch normalization and a higher dropout rate (0.5) before the final classification layer. This architecture significantly outperforms the simpler CFAR model by incorporating modern deep learning techniques like batch normalization and employing a deeper structure for more sophisticated feature extraction.\n\nCode link: deployment/image_classification/CNN/train_pokemon_classifier_cnn.py\nHyperparameters:\n\nLearning rate: 0.001 (with reduction on plateau)\nBatch size: 32\nImage size: 64x64 pixels\nDropout rates: 0.25 for convolutional layers, 0.5 for dense layer\nData augmentation parameters: rotation, shifts, shear, zoom, horizontal flip\n\n\n\n\n\nThe third and most effective model uses EfficientNetB0, a modern and scalable convolutional neural network architecture pre-trained on the ImageNet dataset. Through transfer learning, the model leverages learned visual features and adapts them to the Pokémon image classification task with minimal training from scratch.\nTraining was conducted in two phases:\n\nPhase 1: The EfficientNetB0 base was frozen, and only the custom classification head was trained.\n\nPhase 2: The base model was partially unfrozen and fine-tuned using a lower learning rate.\n\nTo improve generalization, a strong data augmentation pipeline was applied. This increased the model’s robustness to real-world image variability such as different lighting, angles, and scales.\n\nAugmentation techniques included:\n\nRandom horizontal flipping\n\nRandom rotation\n\nRandom zoom\n\nContrast adjustment\n\nBrightness adjustment\n\n\nThe model architecture consists of EfficientNetB0 (with include_top=False) as the feature extractor, followed by:\n\nGlobal Average Pooling to reduce dimensionality\n\nA Dense layer with 128 neurons and ReLU activation\n\nDropout layer (rate: 0.5) to prevent overfitting\n\nA Softmax output layer for multi-class classification\n\n\n\n\nInput shape: 224x224x3 RGB images\n\nLoss function: Sparse categorical cross-entropy\n\nOptimizer: Adam\n\nLearning rate: 1e-4 (frozen base), 1e-5 (fine-tuning)\n\n\nBatch size: 16\n\nTraining epochs: 40 (early stopping applied)\n\nCallbacks:\n\nEarlyStopping with patience=5 and weight restoration\nCustom callback SaveEveryN saving checkpoints every 10 epochs\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[224x224x3 RGB Image]\n    end\n \n    subgraph aug [Data Augmentation]\n    A1[Random Flip] --&gt; A2[Random Rotation]\n    A2 --&gt; A3[Random Zoom]\n    A3 --&gt; A4[Random Contrast]\n    A4 --&gt; A5[Random Brightness]\n    end\n \n    subgraph preproc [Preprocessing]\n    P[EfficientNet Preprocessing]\n    end\n \n    subgraph base [Base Model]\n    EB[EfficientNetB0 Pretrained\\non ImageNet]\n    end\n \n    subgraph head [Classification Head]\n    GAP[Global Average Pooling] --&gt; D1[Dense 128]\n    D1 --&gt; DO[Dropout 0.5]\n    DO --&gt; Out[Output Layer]\n    end\n \n    subgraph training [Training Process]\n    T1[Phase 1: Frozen Base\\n40 Epochs, LR=1e-4] --&gt; T2[Phase 2: Fine-tuning\\nLower LR=1e-5]\n    end\n \n    I --&gt; A1\n    A5 --&gt; P\n    P --&gt; EB\n    EB --&gt; GAP\n    Out --&gt; training\n \n    style input fill:#e1f5fe\n    style aug fill:#fff9c4\n    style preproc fill:#f3e5f5\n    style base fill:#ffccbc\n    style head fill:#e8f5e9\n    style training fill:#e0f2f1\n\n\n\n\n\n\nThis diagram shows the entire processing pipeline: the input image is augmented, preprocessed, passed through the EfficientNetB0 base model, and finally classified through a custom dense head. The two-phase training approach ensures both rapid convergence and effective fine-tuning.\n\n\n\n\n\nThe performance of each model varies based on their architecture complexity and training approach. Our model development followed an iterative process: we first implemented the lightweight CFAR model alongside a basic CNN architecture. Based on the promising results of the CNN approach, we further refined the CNN architecture by adding batch normalization, dropout layers, and implementing double convolution patterns. As a third strategy, we adopted transfer learning by training an EfficientNetB0 pre-trained model to expand our comparison of different deep learning approaches.\n\n\n\nTraining accuracy: ~95%\nValidation accuracy: ~24%\nSimple architecture leads to faster training but lower accuracy\nBest suited for quick prototyping or when computational resources are limited\n\n\n\n\nTraining History for CFAR Model\n\n\nThe figure above shows the training history of the CFAR model over 30 epochs. The left plot displays accuracy metrics, where training accuracy (blue line) steadily increases to approximately 95% while validation accuracy (orange line) plateaus around 24%, indicating significant overfitting. The right plot shows loss metrics, with training loss (blue) decreasing to near zero while validation loss (orange) increases dramatically after the initial epochs, further confirming the model’s poor generalization abilities.\n\n\n\n\nTraining accuracy: ~70-75%\nValidation accuracy: ~65%\nThe addition of batch normalization and dropout layers significantly reduces overfitting\nMultiple convolutional layers allow for hierarchical feature learning\nEarly stopping and learning rate reduction help optimize training\nVisualization tools provide insights into training progress\n\n\n\n\nTraining History for CNN Model\n\n\nThe figure above illustrates the CNN model’s training history over 50 epochs. The accuracy plot (left) shows a more balanced progression between training (blue) and test/validation (orange) accuracy, both reaching approximately 70-75%. The loss plot (right) demonstrates how both training and test losses decrease steadily and remain relatively close together throughout training. This indicates the CNN model achieves better generalization performance than the CFAR model, with the regularization techniques (batch normalization and dropout) effectively mitigating overfitting.\n\n\n\n\nTraining accuracy: ~45%\nValidation accuracy: ~65%\nTwo-phase training approach allows for fine-tuning while avoiding catastrophic forgetting\nHigher resolution input (224x224) captures more details but requires more computational resources\n\n\n\n\nAccuracy over Epochs for Pre-trained EfficientNetB0 Model\n\n\nThis graph shows the EfficientNetB0 model’s training performance over 50 epochs. The validation accuracy (orange) improves rapidly in early epochs, demonstrating transfer learning’s efficiency. We observe a drop at epoch 40 during the transition from Phase 1 (frozen base) to Phase 2 (fine-tuning), followed by quick recovery. Final validation accuracy reaches ~65%, confirming our two-phase approach effectively adapts pre-trained knowledge to Pokémon classification while preventing catastrophic forgetting.\n\n\n\n\nOur experiments with three architectures yield clear insights: - EfficientNetB0 currently performs similarly to our CNN (~65% validation accuracy), but has significantly greater potential for improvement through further fine-tuning - CNN offers balanced performance-resource trade-off (65% accuracy with moderate training time) - CFAR provides rapid prototyping capability but suffers from significant overfitting - Data augmentation is essential for all models to generalize effectively - EfficientNetB0’s pre-trained knowledge can be better leveraged with more extensive adaptation techniques\n\n\n\nWhile both CNN and EfficientNetB0 models currently achieve similar performance (~65% validation accuracy), we recommend the EfficientNetB0 model for deployment due to its greater potential for optimization. Our three-model approach demonstrates that transfer learning offers a promising path forward for Pokémon image classification, especially with additional fine-tuning.\n\n\n\nCurrent performance of all models depends on dataset quality and diversity\nVisually similar Pokémon remain challenging to differentiate\nEfficientNetB0 requires more computational resources but has significant room for improvement\nFurther fine-tuning of the pre-trained layers is necessary to fully leverage ImageNet knowledge\n\n\n\n\n\nMore extensive fine-tuning of EfficientNetB0, especially unfreezing more layers gradually\nExpand dataset diversity with more poses and environments\nExplore more advanced transfer learning techniques to better adapt ImageNet knowledge\nOptimize for mobile via model quantization\nImplement more sophisticated data augmentation techniques specifically for Pokémon images\nDevelop model ensembles combining CNN and EfficientNetB0 strengths\n\n\n\n\n\nGUI testing application already developed (pokemon_classifier_app.py) for internal validation\nWeb-based interface for online Pokémon recognition via our website",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "deeplearning_report.html#initial-situation",
    "href": "deeplearning_report.html#initial-situation",
    "title": "Deep Learning Report",
    "section": "",
    "text": "Our aim for the deep learning component is to accurately identify Pokémon from images, which complements the battle prediction system. This visual recognition capability allows users to upload images of Pokémon they encounter and get immediate battle strategy recommendations.\nThe dataset used consists of Pokémon images collected from various sources and organized into a structured format in the data_acquisition/image_dataset/final_pokemon_dataset directory, with separate train and test folders.\nOur independent variables are the pixel values of the Pokémon images, and our dependent variable is the Pokémon species label. We created three different deep learning models: a CFAR (Convolutional Filter and Response) model, a custom CNN (Convolutional Neural Network), and a pre-trained transfer learning model using EfficientNetB0.\n\nAim of the modeling: Create an accurate image classifier that can identify Pokémon species from images\nDataset used: Collection of Pokémon images organized by species in the final_pokemon_dataset folder\nIndependent variables: Image pixel values (RGB channels)\nTarget variable: Pokémon species name\nTypes of models used: CFAR, CNN, and pre-trained EfficientNetB0",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "deeplearning_report.html#model-descriptions",
    "href": "deeplearning_report.html#model-descriptions",
    "title": "Deep Learning Report",
    "section": "",
    "text": "This section provides an overview of the three deep learning models implemented for Pokémon image classification.\n\n\nThe CFAR (Convolutional Filter and Response) model is a lightweight convolutional neural network designed for basic Pokémon image classification.\n\nImplementation details:\n\nLibrary: TensorFlow/Keras\nInput shape: 64x64x3 (RGB images)\nArchitecture:\n\n3 convolutional layers (32, 64, and 128 filters)\n3 max pooling layers\n1 dense hidden layer (256 neurons)\nOutput layer with softmax activation\n\nOptimizer: Adam\nLoss function: Categorical cross-entropy\nTraining: 30 epochs with validation after each epoch\n\nModeling pipeline:\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[64x64x3 RGB Image]\n    end\n    \n    subgraph conv1 [Layer 1]\n    C1[Conv2D 32 Filters] --&gt; MP1[MaxPooling]\n    end\n    \n    subgraph conv2 [Layer 2]\n    C2[Conv2D 64 Filters] --&gt; MP2[MaxPooling]\n    end\n    \n    subgraph conv3 [Layer 3]\n    C3[Conv2D 128 Filters] --&gt; MP3[MaxPooling]\n    end\n    \n    subgraph dense [Dense Layers]\n    F[Flatten] --&gt; D1[Dense 256 neurons]\n    D1 --&gt; Out[Output Layer]\n    end\n    \n    I --&gt; C1\n    MP1 --&gt; C2\n    MP2 --&gt; C3\n    MP3 --&gt; F\n    \n    style input fill:#e1f5fe\n    style conv1 fill:#ffecb3\n    style conv2 fill:#ffecb3\n    style conv3 fill:#ffecb3\n    style dense fill:#e8f5e9\n\n\n\n\n\n\nThe diagram above illustrates the architecture of the CFAR model. Starting with an input RGB image (64x64x3), the data flows through three convolutional layers with increasing filter sizes (32, 64, and 128), each followed by a MaxPooling operation to reduce dimensionality. The feature maps from the final convolutional layer are flattened and passed through a dense layer with 256 neurons, which connects to the output layer for classification. This sequential structure enables the model to progressively extract and refine features from the input images before making the final classification decision.\n\nCode link: deployment/image_classification/cfar/train_pokemon_classifier_cfar.py\nHyperparameters:\n\nLearning rate: Default for Adam optimizer\nBatch size: 32\nImage size: 64x64 pixels\nNo data augmentation\n\n\n\n\n\nThe CNN model is a more advanced deep learning architecture with multiple convolutional layers designed for improved feature extraction and classification accuracy.\n\nImplementation details:\n\nLibrary: TensorFlow/Keras\nInput shape: 64x64x3 (RGB images)\nArchitecture:\n\n4 convolutional layers with batch normalization and dropout\nEach layer has double convolution layers with increasing filter sizes (32→64→128→256)\nMax pooling after each layer\nFlatten layer followed by dense layer (512 neurons)\nOutput layer with softmax activation\n\nOptimizer: Adam with configurable learning rate\nLoss function: Categorical cross-entropy\nTraining: Up to 80 epochs with early stopping and learning rate reduction\n\nModeling pipeline:\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[64x64x3 RGB Image]\n    end\n    \n    subgraph aug [Data Augmentation]\n    A1[Random Rotation] --&gt; A2[Width/Height Shifts]\n    A2 --&gt; A3[Shear Transform]\n    A3 --&gt; A4[Zoom]\n    A4 --&gt; A5[Horizontal Flip]\n    end\n    \n    subgraph conv1 [Layer 1]\n    C1A[Conv2D 32] --&gt; BN1A[BatchNorm]\n    BN1A --&gt; C1B[Conv2D 32] \n    C1B --&gt; BN1B[BatchNorm]\n    BN1B --&gt; MP1[MaxPooling]\n    MP1 --&gt; D1[Dropout 0.25]\n    end\n    \n    subgraph conv2 [Layer 2]\n    C2A[Conv2D 64] --&gt; BN2A[BatchNorm]\n    BN2A --&gt; C2B[Conv2D 64] \n    C2B --&gt; BN2B[BatchNorm]\n    BN2B --&gt; MP2[MaxPooling]\n    MP2 --&gt; D2[Dropout 0.25]\n    end\n    \n    subgraph conv3 [Layer 3]\n    C3A[Conv2D 128] --&gt; BN3A[BatchNorm]\n    BN3A --&gt; C3B[Conv2D 128] \n    C3B --&gt; BN3B[BatchNorm]\n    BN3B --&gt; MP3[MaxPooling]\n    MP3 --&gt; D3[Dropout 0.25]\n    end\n    \n    subgraph conv4 [Layer 4]\n    C4A[Conv2D 256] --&gt; BN4A[BatchNorm]\n    BN4A --&gt; C4B[Conv2D 256] \n    C4B --&gt; BN4B[BatchNorm]\n    BN4B --&gt; MP4[MaxPooling]\n    MP4 --&gt; D4[Dropout 0.25]\n    end\n    \n    subgraph dense [Dense Layers]\n    F[Flatten] --&gt; DL1[Dense 512]\n    DL1 --&gt; BN5[BatchNorm]\n    BN5 --&gt; D5[Dropout 0.5]\n    D5 --&gt; Out[Output Layer]\n    end\n    \n    I --&gt; A1\n    A5 --&gt; C1A\n    D1 --&gt; C2A\n    D2 --&gt; C3A\n    D3 --&gt; C4A\n    D4 --&gt; F\n    \n    style input fill:#e1f5fe\n    style aug fill:#e8f5e9\n    style conv1 fill:#ffecb3\n    style conv2 fill:#ffe082\n    style conv3 fill:#ffd54f\n    style conv4 fill:#ffca28\n    style dense fill:#e8f5e9\n\n\n\n\n\n\nThe diagram above illustrates the more complex CNN architecture used for Pokémon classification. This model features four convolutional layers with progressively increasing filter sizes (32→64→128→256), each implementing a double convolution pattern. The pipeline begins with data augmentation techniques (rotation, shifts, shear, zoom, and flipping) that enhance the training dataset and improve generalization. Every layer follows the same structure: two convolutional layers, each followed by batch normalization, then max pooling, and finally dropout (0.25) to prevent overfitting. After the convolutional layers, the data is flattened and passed through a dense layer with 512 neurons, followed by batch normalization and a higher dropout rate (0.5) before the final classification layer. This architecture significantly outperforms the simpler CFAR model by incorporating modern deep learning techniques like batch normalization and employing a deeper structure for more sophisticated feature extraction.\n\nCode link: deployment/image_classification/CNN/train_pokemon_classifier_cnn.py\nHyperparameters:\n\nLearning rate: 0.001 (with reduction on plateau)\nBatch size: 32\nImage size: 64x64 pixels\nDropout rates: 0.25 for convolutional layers, 0.5 for dense layer\nData augmentation parameters: rotation, shifts, shear, zoom, horizontal flip\n\n\n\n\n\nThe third and most effective model uses EfficientNetB0, a modern and scalable convolutional neural network architecture pre-trained on the ImageNet dataset. Through transfer learning, the model leverages learned visual features and adapts them to the Pokémon image classification task with minimal training from scratch.\nTraining was conducted in two phases:\n\nPhase 1: The EfficientNetB0 base was frozen, and only the custom classification head was trained.\n\nPhase 2: The base model was partially unfrozen and fine-tuned using a lower learning rate.\n\nTo improve generalization, a strong data augmentation pipeline was applied. This increased the model’s robustness to real-world image variability such as different lighting, angles, and scales.\n\nAugmentation techniques included:\n\nRandom horizontal flipping\n\nRandom rotation\n\nRandom zoom\n\nContrast adjustment\n\nBrightness adjustment\n\n\nThe model architecture consists of EfficientNetB0 (with include_top=False) as the feature extractor, followed by:\n\nGlobal Average Pooling to reduce dimensionality\n\nA Dense layer with 128 neurons and ReLU activation\n\nDropout layer (rate: 0.5) to prevent overfitting\n\nA Softmax output layer for multi-class classification\n\n\n\n\nInput shape: 224x224x3 RGB images\n\nLoss function: Sparse categorical cross-entropy\n\nOptimizer: Adam\n\nLearning rate: 1e-4 (frozen base), 1e-5 (fine-tuning)\n\n\nBatch size: 16\n\nTraining epochs: 40 (early stopping applied)\n\nCallbacks:\n\nEarlyStopping with patience=5 and weight restoration\nCustom callback SaveEveryN saving checkpoints every 10 epochs\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    subgraph input [Input]\n    I[224x224x3 RGB Image]\n    end\n \n    subgraph aug [Data Augmentation]\n    A1[Random Flip] --&gt; A2[Random Rotation]\n    A2 --&gt; A3[Random Zoom]\n    A3 --&gt; A4[Random Contrast]\n    A4 --&gt; A5[Random Brightness]\n    end\n \n    subgraph preproc [Preprocessing]\n    P[EfficientNet Preprocessing]\n    end\n \n    subgraph base [Base Model]\n    EB[EfficientNetB0 Pretrained\\non ImageNet]\n    end\n \n    subgraph head [Classification Head]\n    GAP[Global Average Pooling] --&gt; D1[Dense 128]\n    D1 --&gt; DO[Dropout 0.5]\n    DO --&gt; Out[Output Layer]\n    end\n \n    subgraph training [Training Process]\n    T1[Phase 1: Frozen Base\\n40 Epochs, LR=1e-4] --&gt; T2[Phase 2: Fine-tuning\\nLower LR=1e-5]\n    end\n \n    I --&gt; A1\n    A5 --&gt; P\n    P --&gt; EB\n    EB --&gt; GAP\n    Out --&gt; training\n \n    style input fill:#e1f5fe\n    style aug fill:#fff9c4\n    style preproc fill:#f3e5f5\n    style base fill:#ffccbc\n    style head fill:#e8f5e9\n    style training fill:#e0f2f1\n\n\n\n\n\n\nThis diagram shows the entire processing pipeline: the input image is augmented, preprocessed, passed through the EfficientNetB0 base model, and finally classified through a custom dense head. The two-phase training approach ensures both rapid convergence and effective fine-tuning.",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "deeplearning_report.html#results",
    "href": "deeplearning_report.html#results",
    "title": "Deep Learning Report",
    "section": "",
    "text": "The performance of each model varies based on their architecture complexity and training approach. Our model development followed an iterative process: we first implemented the lightweight CFAR model alongside a basic CNN architecture. Based on the promising results of the CNN approach, we further refined the CNN architecture by adding batch normalization, dropout layers, and implementing double convolution patterns. As a third strategy, we adopted transfer learning by training an EfficientNetB0 pre-trained model to expand our comparison of different deep learning approaches.\n\n\n\nTraining accuracy: ~95%\nValidation accuracy: ~24%\nSimple architecture leads to faster training but lower accuracy\nBest suited for quick prototyping or when computational resources are limited\n\n\n\n\nTraining History for CFAR Model\n\n\nThe figure above shows the training history of the CFAR model over 30 epochs. The left plot displays accuracy metrics, where training accuracy (blue line) steadily increases to approximately 95% while validation accuracy (orange line) plateaus around 24%, indicating significant overfitting. The right plot shows loss metrics, with training loss (blue) decreasing to near zero while validation loss (orange) increases dramatically after the initial epochs, further confirming the model’s poor generalization abilities.\n\n\n\n\nTraining accuracy: ~70-75%\nValidation accuracy: ~65%\nThe addition of batch normalization and dropout layers significantly reduces overfitting\nMultiple convolutional layers allow for hierarchical feature learning\nEarly stopping and learning rate reduction help optimize training\nVisualization tools provide insights into training progress\n\n\n\n\nTraining History for CNN Model\n\n\nThe figure above illustrates the CNN model’s training history over 50 epochs. The accuracy plot (left) shows a more balanced progression between training (blue) and test/validation (orange) accuracy, both reaching approximately 70-75%. The loss plot (right) demonstrates how both training and test losses decrease steadily and remain relatively close together throughout training. This indicates the CNN model achieves better generalization performance than the CFAR model, with the regularization techniques (batch normalization and dropout) effectively mitigating overfitting.\n\n\n\n\nTraining accuracy: ~45%\nValidation accuracy: ~65%\nTwo-phase training approach allows for fine-tuning while avoiding catastrophic forgetting\nHigher resolution input (224x224) captures more details but requires more computational resources\n\n\n\n\nAccuracy over Epochs for Pre-trained EfficientNetB0 Model\n\n\nThis graph shows the EfficientNetB0 model’s training performance over 50 epochs. The validation accuracy (orange) improves rapidly in early epochs, demonstrating transfer learning’s efficiency. We observe a drop at epoch 40 during the transition from Phase 1 (frozen base) to Phase 2 (fine-tuning), followed by quick recovery. Final validation accuracy reaches ~65%, confirming our two-phase approach effectively adapts pre-trained knowledge to Pokémon classification while preventing catastrophic forgetting.",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "deeplearning_report.html#model-interpretation",
    "href": "deeplearning_report.html#model-interpretation",
    "title": "Deep Learning Report",
    "section": "",
    "text": "Our experiments with three architectures yield clear insights: - EfficientNetB0 currently performs similarly to our CNN (~65% validation accuracy), but has significantly greater potential for improvement through further fine-tuning - CNN offers balanced performance-resource trade-off (65% accuracy with moderate training time) - CFAR provides rapid prototyping capability but suffers from significant overfitting - Data augmentation is essential for all models to generalize effectively - EfficientNetB0’s pre-trained knowledge can be better leveraged with more extensive adaptation techniques",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "deeplearning_report.html#conclusions-and-next-steps",
    "href": "deeplearning_report.html#conclusions-and-next-steps",
    "title": "Deep Learning Report",
    "section": "",
    "text": "While both CNN and EfficientNetB0 models currently achieve similar performance (~65% validation accuracy), we recommend the EfficientNetB0 model for deployment due to its greater potential for optimization. Our three-model approach demonstrates that transfer learning offers a promising path forward for Pokémon image classification, especially with additional fine-tuning.\n\n\n\nCurrent performance of all models depends on dataset quality and diversity\nVisually similar Pokémon remain challenging to differentiate\nEfficientNetB0 requires more computational resources but has significant room for improvement\nFurther fine-tuning of the pre-trained layers is necessary to fully leverage ImageNet knowledge\n\n\n\n\n\nMore extensive fine-tuning of EfficientNetB0, especially unfreezing more layers gradually\nExpand dataset diversity with more poses and environments\nExplore more advanced transfer learning techniques to better adapt ImageNet knowledge\nOptimize for mobile via model quantization\nImplement more sophisticated data augmentation techniques specifically for Pokémon images\nDevelop model ensembles combining CNN and EfficientNetB0 strengths\n\n\n\n\n\nGUI testing application already developed (pokemon_classifier_app.py) for internal validation\nWeb-based interface for online Pokémon recognition via our website",
    "crumbs": [
      "Deep Learning Report"
    ]
  },
  {
    "objectID": "data_report.html",
    "href": "data_report.html",
    "title": "Data Report",
    "section": "",
    "text": "All information on the data used in the Pokemon GO Battle Assistant project is compiled in this data report to ensure traceability and reproducibility of the results and to enable systematic expansion of the database.\nThe project utilizes three main data sources: Pokemon statistics and moves from the PvPoke rankings site, battle simulation data from the PvPoke battles site, and image datasets collected through the Python library duckduckgo_search. These raw datasets undergo preprocessing and feature engineering to create processed datasets suitable for machine learning model development.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nSource\nStorage location\n\n\n\n\nPokemon Stats & Rankings\nPvPoke.com CSV dataset\ndata_acquisition/processed_data/all_overall_rankings.csv\n\n\nBattle Simulation Data\nPvPoke.com Battle Simulator\ndata_acquisition/vectorized_data/battle_data_numeric.csv\n\n\nPokemon Image Dataset\nDuckDuckGo Search API, PokémonDB, coloringpages101.com\ndata_acquisition/image_dataset/final_pokemon_dataset/\n\n\n\nNote: The Pokemon Stats & Rankings dataset was subsequently vectorized and stored as all_overall_rankings_vectorized.csv in the data_acquisition/vectorized_data/ directory for machine learning model development.\n\n\n\n\nDescription: Contains comprehensive Pokemon statistics, battle performance metrics, movesets, and meta rankings for PvP battles\nData source:\n\nOriginally: PvPoke.com rankings page via web scraping\nFinal source: Comprehensive CSV dataset from PvPoke.com with detailed Pokemon battle statistics\n\nData procurement:\n\nInitial approach: Web scraping using Selenium WebDriver and BeautifulSoup\n\nAutomated extraction of Pokemon attack/defense/stamina stats, fast moves, charged moves, and recommended movesets\nScripts: Poke_stats_Scraper.ipynb\n\nFinal approach: Found a more comprehensive CSV dataset with detailed battle metrics and Pokemon parameters\n\nThis dataset provided extensive information including Stat Product, CP, Level, Charged Move Counts, and Buddy Distance\n\n\nLegal aspects: Public data available for educational/research purposes\nData governance: Public data, no personal information\nVariables: Pokemon name, Score, Pokedex number, Type 1 & 2, Attack, Defense, Stamina stats, Stat Product, CP, Fast Move, Charged Moves, Charged Move Counts, Buddy Distance, Charged Move Cost\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\nPokemon\nString\nPokemon species names\nUnique identifier for each Pokemon\n\n\n2\nScore\nFloat\n0-100\nOverall battle performance rating\n\n\n3\nDex\nInteger\n1-1000+\nPokedex number identifier\n\n\n4\nType 1\nString\nPokemon type name\nPrimary type of the Pokemon\n\n\n5\nType 2\nString\nPokemon type name or “none”\nSecondary type of the Pokemon (if any)\n\n\n6\nAttack\nFloat\n50-300\nAttack stat value\n\n\n7\nDefense\nFloat\n50-300\nDefense stat value\n\n\n8\nStamina\nInteger\n80-500\nHP/Stamina stat value\n\n\n9\nStat Product\nInteger\n1000000-3000000\nCombined stat product (Attack × Defense × Stamina)\n\n\n10\nLevel\nFloat\n1-50\nPokemon level for battle league\n\n\n11\nCP\nInteger\n0-1500\nCombat Power value\n\n\n12\nFast Move\nString\nMove names\nFast attack move for battle\n\n\n13\nCharged Move 1\nString\nMove names\nPrimary charged attack move\n\n\n14\nCharged Move 2\nString\nMove names\nSecondary charged attack move\n\n\n15\nCharged Move 1 Count\nInteger\n1-20+\nEnergy requirement for Charged Move 1\n\n\n16\nCharged Move 2 Count\nInteger\n1-20+\nEnergy requirement for Charged Move 2\n\n\n17\nBuddy Distance\nInteger\n1-20\nWalking distance (km) required as buddy\n\n\n18\nCharged Move Cost\nInteger\n10000-100000\nStardust cost to unlock second charged move\n\n\n\n\n\n\n\nCompleteness: 727 unique Pokemon entries with complete stat information in the final dataset\nAccuracy: Data validated against official game statistics\nConsistency: Standardized naming conventions and data formats\nDuplicates: No duplicates in the final dataset (originally found 2 duplicate entries - Clodsire, Golisopod)\n\n\n\n\n\n\nDescription: Contains vectorized numeric data from simulated 1v1 Pokemon battles for predicting battle outcomes\nData source: PvPoke.com battle simulator combined with Pokemon statistics dataset\nData procurement:\n\nWeb scraping using Selenium WebDriver\n20,000 battle scenarios simulated (generated using random sampling with Python’s random number generator)\n\nLegal aspects: Public simulation tool, data used for educational purposes\nData governance: Public data, computational results from simulator\nVariables: Pokemon types, moves, stats, and battle outcomes (win/loss)\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\npokemon_winner\nString\nPokemon species name\nWinner Pokemon name\n\n\n2\npokemon_loser\nString\nPokemon species name\nLoser Pokemon name\n\n\n3\nleft_pokemon_type_1\nInteger\n0-17\nPrimary type of left Pokemon (encoded)\n\n\n4\nleft_pokemon_type_2\nInteger\n0-17\nSecondary type of left Pokemon (encoded)\n\n\n5\nleft_pokemon_fast_move\nInteger\nMove ID\nFast move ID of left Pokemon\n\n\n6\nleft_pokemon_charge_move_1\nInteger\nMove ID\nFirst charged move ID of left Pokemon\n\n\n7\nleft_pokemon_charge_move_2\nInteger\nMove ID\nSecond charged move ID of left Pokemon\n\n\n8\nleft_pokemon_fast_move_type\nInteger\n0-17\nType of fast move for left Pokemon (encoded)\n\n\n9\nleft_pokemon_charge_move_1_type\nInteger\n0-17\nType of first charged move for left Pokemon\n\n\n10\nleft_pokemon_charge_move_2_type\nInteger\n0-17\nType of second charged move for left Pokemon\n\n\n11\nleft_pokemon_dex\nInteger\n1-1000+\nPokedex number of left Pokemon\n\n\n12\nleft_pokemon_attack\nFloat\n0.0-300.0\nAttack stat of left Pokemon\n\n\n13\nleft_pokemon_defense\nFloat\n0.0-300.0\nDefense stat of left Pokemon\n\n\n14\nleft_pokemon_stamina\nInteger\n0-500\nStamina stat of left Pokemon\n\n\n15\nleft_pokemon_overall\nFloat\n0.0-100.0\nOverall performance rating of left Pokemon\n\n\n16\nright_pokemon_type_1\nInteger\n0-17\nPrimary type of right Pokemon (encoded)\n\n\n17\nright_pokemon_type_2\nInteger\n0-17\nSecondary type of right Pokemon (encoded)\n\n\n18\nright_pokemon_fast_move\nInteger\nMove ID\nFast move ID of right Pokemon\n\n\n19\nright_pokemon_charge_move_1\nInteger\nMove ID\nFirst charged move ID of right Pokemon\n\n\n20\nright_pokemon_charge_move_2\nInteger\nMove ID\nSecond charged move ID of right Pokemon\n\n\n21\nright_pokemon_fast_move_type\nInteger\n0-17\nType of fast move for right Pokemon (encoded)\n\n\n22\nright_pokemon_charge_move_1_type\nInteger\n0-17\nType of first charged move for right Pokemon\n\n\n23\nright_pokemon_charge_move_2_type\nInteger\n0-17\nType of second charged move for right Pokemon\n\n\n24\nright_pokemon_dex\nInteger\n1-1000+\nPokedex number of right Pokemon\n\n\n25\nright_pokemon_attack\nFloat\n0.0-300.0\nAttack stat of right Pokemon\n\n\n26\nright_pokemon_defense\nFloat\n0.0-300.0\nDefense stat of right Pokemon\n\n\n27\nright_pokemon_stamina\nInteger\n0-500\nStamina stat of right Pokemon\n\n\n28\nright_pokemon_overall\nFloat\n0.0-100.0\nOverall performance rating of right Pokemon\n\n\n29\nwinner\nInteger\n0 or 1\nBattle outcome (1 = left Pokemon wins, 0 = right)\n\n\n\n\n\n\n\nCompleteness: 20,000 battles with complete information for both Pokemon\nBalance: Near-equal distribution of win/loss outcomes for predictive modeling\nConsistency: All categorical variables consistently encoded using reference dictionaries\nPreprocessing: All features numerically encoded for direct use in machine learning models\n\n\n\n\n\n\n\n\n\n\n\nDataset 3 was created to build a diverse, high-quality, and robust Pokémon image dataset, suitable for applications in computer vision such as object detection, classification, and few-shot learning. The focus was on:\n\nIntegrating multiple complementary data sources (official and unofficial)\nRemoving duplicates using hash-based similarity checks\nEnsuring high data quality through manual and automated filtering\nApplying structured post-processing and dataset organization\n\n\n\n\n\nThe images were collected via custom Python scripts from three distinct sources\n\n\n\nDataset Generation Process\n\n\n\n\n\nScript: scrape_official_sprites.py\n\nUp to 16 different sprite sets per Pokémon (e.g., red-blue, home, scarlet-violet)\n\nShadow forms were excluded\n\nStored in Pokémon-specific subfolders with SHA256-based filenames to prevent duplication\n\n\n\n\n\nScript: scrape_coloring_pages.py\n\nAutomatically crawled category and detail pages using regular expressions and name normalization\nDownloaded all available PNG files into the corresponding Pokémon folders\n\nThese black-and-white line drawings have clean, high-contrast edges — ideal for training models on shape or contour recognition\n\n\n\n\n\nScript: image_downloader_ddg.py\n\nTarget: at least 30 visually distinct images per Pokémon\n\nDuplicate filtering:\n\nByte-level: SHA256 hash\nVisual-level: Perceptual hash (phash) with Hamming distance ≤ 5\n\n\nImages were compressed and stored as JPEGs (quality = 50%) for storage efficiency\n\n\n\n\n\n\n\n\n\nScript: rename_images_by_hash.py\n\nAll images renamed based on their perceptual hash\n\nEnsures uniqueness, removes duplicates, and enforces naming consistency\n\n\n\n\n\nTool: image_review_gui.py (built with PyQt5)\n\nDesktop tool for manually inspecting, selecting, and cropping images\n\nKey use case: cropping Pokémon card images to isolate just the artwork and remove backgrounds or frames\n\nFeatures:\n\nGrid-based image preview (8 columns)\nMulti-selection and cropping (overwrite original files)\nProgress tracking with done_folders.json\nDual-person workflow (folders are split between two users via a simple flag)\n\n\n\n\n\n\nScript: split_train_test_dataset.py\n\nAutomatically splits each Pokémon folder into an 80% training and 20% test set\n\nThe split is performed randomly to ensure unbiased distribution of images\n\nFinal structure reflects common deep learning pipelines\n\n\n\n\n\n\nThe dataset is organized into a standard structure for supervised image classification. The root folder final_pokemon_dataset/ contains two subfolders: train/ and test/, representing an 80:20 split.\nproject_root/\n├── final_pokemon_dataset/\n│   ├── train/\n│   │   └── Abomasnow/\n│   │   └── Electabuzz/\n│   │   └── Totodile/\n│   │   ...\n│   └── test/\n│       └── Abomasnow/\n│       └── Electabuzz/\n│       └── Totodile/\n│       ...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nSource\nStorage location\n\n\n\n\nVectorized Pokemon Dataset\nPokemon Stats & Rankings\ndata_acquisition/vectorized_data/all_overall_rankings_vectorized.csv\n\n\nBattle Outcome Dataset\nBattle Simulation Data\ndata_acquisition/vectorized_data/battle_data_numeric.csv\n\n\nImage Training Dataset\nPokemon Image Dataset\ndata_acquisition/image_dataset/final_pokemon_dataset/\n\n\n\n\n\n\n\nDescription: Vectorized version of the Pokemon Stats & Rankings dataset for machine learning applications\nProcessing steps:\n\nRemoval of duplicate entries\nVectorization of categorical features (Pokemon types, moves)\nFeature engineering: type effectiveness calculations, stat ratios, move type diversity\nEncoding of categorical variables using numerical mapping dictionaries\nNormalization of numerical features\nPreparation for model input\n\nVectorization process:\n\nCategorical features converted to numerical representations using mapping dictionaries\nTypes, fast moves, and charged moves encoded using dedicated mapping files:\n\ndata_acquisition/dictionarie/type_to_number.csv\ndata_acquisition/dictionarie/fast_move_to_number.csv\ndata_acquisition/dictionarie/charged_move_to_number.csv\n\nVectorization performed in pokemon_vectorization.ipynb\n\nAccess method: CSV file accessible via pandas DataFrame loading\n\n\n\n\nVectorized feature set with all categorical variables converted to numerical representations\nStandardized numerical ranges for model compatibility\nPreserves all information from the original dataset in machine learning-ready format\n\n\n\n\n\n\nDescription: The battle_data_numeric.csv dataset is already processed and ready for machine learning\nProcessing steps:\n\nCategorical variables (Pokemon types, moves) numerically encoded using reference dictionaries\nFeature pairing to represent both Pokemon in each battle scenario\nBalancing of win/loss outcomes for unbiased model training\nNormalization of numerical features where appropriate\n\nAccess method: Structured CSV with all features in numeric format, directly suitable for ML model training",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#raw-data",
    "href": "data_report.html#raw-data",
    "title": "Data Report",
    "section": "",
    "text": "Name\nSource\nStorage location\n\n\n\n\nPokemon Stats & Rankings\nPvPoke.com CSV dataset\ndata_acquisition/processed_data/all_overall_rankings.csv\n\n\nBattle Simulation Data\nPvPoke.com Battle Simulator\ndata_acquisition/vectorized_data/battle_data_numeric.csv\n\n\nPokemon Image Dataset\nDuckDuckGo Search API, PokémonDB, coloringpages101.com\ndata_acquisition/image_dataset/final_pokemon_dataset/\n\n\n\nNote: The Pokemon Stats & Rankings dataset was subsequently vectorized and stored as all_overall_rankings_vectorized.csv in the data_acquisition/vectorized_data/ directory for machine learning model development.\n\n\n\n\nDescription: Contains comprehensive Pokemon statistics, battle performance metrics, movesets, and meta rankings for PvP battles\nData source:\n\nOriginally: PvPoke.com rankings page via web scraping\nFinal source: Comprehensive CSV dataset from PvPoke.com with detailed Pokemon battle statistics\n\nData procurement:\n\nInitial approach: Web scraping using Selenium WebDriver and BeautifulSoup\n\nAutomated extraction of Pokemon attack/defense/stamina stats, fast moves, charged moves, and recommended movesets\nScripts: Poke_stats_Scraper.ipynb\n\nFinal approach: Found a more comprehensive CSV dataset with detailed battle metrics and Pokemon parameters\n\nThis dataset provided extensive information including Stat Product, CP, Level, Charged Move Counts, and Buddy Distance\n\n\nLegal aspects: Public data available for educational/research purposes\nData governance: Public data, no personal information\nVariables: Pokemon name, Score, Pokedex number, Type 1 & 2, Attack, Defense, Stamina stats, Stat Product, CP, Fast Move, Charged Moves, Charged Move Counts, Buddy Distance, Charged Move Cost\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\nPokemon\nString\nPokemon species names\nUnique identifier for each Pokemon\n\n\n2\nScore\nFloat\n0-100\nOverall battle performance rating\n\n\n3\nDex\nInteger\n1-1000+\nPokedex number identifier\n\n\n4\nType 1\nString\nPokemon type name\nPrimary type of the Pokemon\n\n\n5\nType 2\nString\nPokemon type name or “none”\nSecondary type of the Pokemon (if any)\n\n\n6\nAttack\nFloat\n50-300\nAttack stat value\n\n\n7\nDefense\nFloat\n50-300\nDefense stat value\n\n\n8\nStamina\nInteger\n80-500\nHP/Stamina stat value\n\n\n9\nStat Product\nInteger\n1000000-3000000\nCombined stat product (Attack × Defense × Stamina)\n\n\n10\nLevel\nFloat\n1-50\nPokemon level for battle league\n\n\n11\nCP\nInteger\n0-1500\nCombat Power value\n\n\n12\nFast Move\nString\nMove names\nFast attack move for battle\n\n\n13\nCharged Move 1\nString\nMove names\nPrimary charged attack move\n\n\n14\nCharged Move 2\nString\nMove names\nSecondary charged attack move\n\n\n15\nCharged Move 1 Count\nInteger\n1-20+\nEnergy requirement for Charged Move 1\n\n\n16\nCharged Move 2 Count\nInteger\n1-20+\nEnergy requirement for Charged Move 2\n\n\n17\nBuddy Distance\nInteger\n1-20\nWalking distance (km) required as buddy\n\n\n18\nCharged Move Cost\nInteger\n10000-100000\nStardust cost to unlock second charged move\n\n\n\n\n\n\n\nCompleteness: 727 unique Pokemon entries with complete stat information in the final dataset\nAccuracy: Data validated against official game statistics\nConsistency: Standardized naming conventions and data formats\nDuplicates: No duplicates in the final dataset (originally found 2 duplicate entries - Clodsire, Golisopod)\n\n\n\n\n\n\nDescription: Contains vectorized numeric data from simulated 1v1 Pokemon battles for predicting battle outcomes\nData source: PvPoke.com battle simulator combined with Pokemon statistics dataset\nData procurement:\n\nWeb scraping using Selenium WebDriver\n20,000 battle scenarios simulated (generated using random sampling with Python’s random number generator)\n\nLegal aspects: Public simulation tool, data used for educational purposes\nData governance: Public data, computational results from simulator\nVariables: Pokemon types, moves, stats, and battle outcomes (win/loss)\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\npokemon_winner\nString\nPokemon species name\nWinner Pokemon name\n\n\n2\npokemon_loser\nString\nPokemon species name\nLoser Pokemon name\n\n\n3\nleft_pokemon_type_1\nInteger\n0-17\nPrimary type of left Pokemon (encoded)\n\n\n4\nleft_pokemon_type_2\nInteger\n0-17\nSecondary type of left Pokemon (encoded)\n\n\n5\nleft_pokemon_fast_move\nInteger\nMove ID\nFast move ID of left Pokemon\n\n\n6\nleft_pokemon_charge_move_1\nInteger\nMove ID\nFirst charged move ID of left Pokemon\n\n\n7\nleft_pokemon_charge_move_2\nInteger\nMove ID\nSecond charged move ID of left Pokemon\n\n\n8\nleft_pokemon_fast_move_type\nInteger\n0-17\nType of fast move for left Pokemon (encoded)\n\n\n9\nleft_pokemon_charge_move_1_type\nInteger\n0-17\nType of first charged move for left Pokemon\n\n\n10\nleft_pokemon_charge_move_2_type\nInteger\n0-17\nType of second charged move for left Pokemon\n\n\n11\nleft_pokemon_dex\nInteger\n1-1000+\nPokedex number of left Pokemon\n\n\n12\nleft_pokemon_attack\nFloat\n0.0-300.0\nAttack stat of left Pokemon\n\n\n13\nleft_pokemon_defense\nFloat\n0.0-300.0\nDefense stat of left Pokemon\n\n\n14\nleft_pokemon_stamina\nInteger\n0-500\nStamina stat of left Pokemon\n\n\n15\nleft_pokemon_overall\nFloat\n0.0-100.0\nOverall performance rating of left Pokemon\n\n\n16\nright_pokemon_type_1\nInteger\n0-17\nPrimary type of right Pokemon (encoded)\n\n\n17\nright_pokemon_type_2\nInteger\n0-17\nSecondary type of right Pokemon (encoded)\n\n\n18\nright_pokemon_fast_move\nInteger\nMove ID\nFast move ID of right Pokemon\n\n\n19\nright_pokemon_charge_move_1\nInteger\nMove ID\nFirst charged move ID of right Pokemon\n\n\n20\nright_pokemon_charge_move_2\nInteger\nMove ID\nSecond charged move ID of right Pokemon\n\n\n21\nright_pokemon_fast_move_type\nInteger\n0-17\nType of fast move for right Pokemon (encoded)\n\n\n22\nright_pokemon_charge_move_1_type\nInteger\n0-17\nType of first charged move for right Pokemon\n\n\n23\nright_pokemon_charge_move_2_type\nInteger\n0-17\nType of second charged move for right Pokemon\n\n\n24\nright_pokemon_dex\nInteger\n1-1000+\nPokedex number of right Pokemon\n\n\n25\nright_pokemon_attack\nFloat\n0.0-300.0\nAttack stat of right Pokemon\n\n\n26\nright_pokemon_defense\nFloat\n0.0-300.0\nDefense stat of right Pokemon\n\n\n27\nright_pokemon_stamina\nInteger\n0-500\nStamina stat of right Pokemon\n\n\n28\nright_pokemon_overall\nFloat\n0.0-100.0\nOverall performance rating of right Pokemon\n\n\n29\nwinner\nInteger\n0 or 1\nBattle outcome (1 = left Pokemon wins, 0 = right)\n\n\n\n\n\n\n\nCompleteness: 20,000 battles with complete information for both Pokemon\nBalance: Near-equal distribution of win/loss outcomes for predictive modeling\nConsistency: All categorical variables consistently encoded using reference dictionaries\nPreprocessing: All features numerically encoded for direct use in machine learning models",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#dataset-3",
    "href": "data_report.html#dataset-3",
    "title": "Data Report",
    "section": "",
    "text": "Dataset 3 was created to build a diverse, high-quality, and robust Pokémon image dataset, suitable for applications in computer vision such as object detection, classification, and few-shot learning. The focus was on:\n\nIntegrating multiple complementary data sources (official and unofficial)\nRemoving duplicates using hash-based similarity checks\nEnsuring high data quality through manual and automated filtering\nApplying structured post-processing and dataset organization\n\n\n\n\n\nThe images were collected via custom Python scripts from three distinct sources\n\n\n\nDataset Generation Process\n\n\n\n\n\nScript: scrape_official_sprites.py\n\nUp to 16 different sprite sets per Pokémon (e.g., red-blue, home, scarlet-violet)\n\nShadow forms were excluded\n\nStored in Pokémon-specific subfolders with SHA256-based filenames to prevent duplication\n\n\n\n\n\nScript: scrape_coloring_pages.py\n\nAutomatically crawled category and detail pages using regular expressions and name normalization\nDownloaded all available PNG files into the corresponding Pokémon folders\n\nThese black-and-white line drawings have clean, high-contrast edges — ideal for training models on shape or contour recognition\n\n\n\n\n\nScript: image_downloader_ddg.py\n\nTarget: at least 30 visually distinct images per Pokémon\n\nDuplicate filtering:\n\nByte-level: SHA256 hash\nVisual-level: Perceptual hash (phash) with Hamming distance ≤ 5\n\n\nImages were compressed and stored as JPEGs (quality = 50%) for storage efficiency\n\n\n\n\n\n\n\n\n\nScript: rename_images_by_hash.py\n\nAll images renamed based on their perceptual hash\n\nEnsures uniqueness, removes duplicates, and enforces naming consistency\n\n\n\n\n\nTool: image_review_gui.py (built with PyQt5)\n\nDesktop tool for manually inspecting, selecting, and cropping images\n\nKey use case: cropping Pokémon card images to isolate just the artwork and remove backgrounds or frames\n\nFeatures:\n\nGrid-based image preview (8 columns)\nMulti-selection and cropping (overwrite original files)\nProgress tracking with done_folders.json\nDual-person workflow (folders are split between two users via a simple flag)\n\n\n\n\n\n\nScript: split_train_test_dataset.py\n\nAutomatically splits each Pokémon folder into an 80% training and 20% test set\n\nThe split is performed randomly to ensure unbiased distribution of images\n\nFinal structure reflects common deep learning pipelines\n\n\n\n\n\n\nThe dataset is organized into a standard structure for supervised image classification. The root folder final_pokemon_dataset/ contains two subfolders: train/ and test/, representing an 80:20 split.\nproject_root/\n├── final_pokemon_dataset/\n│   ├── train/\n│   │   └── Abomasnow/\n│   │   └── Electabuzz/\n│   │   └── Totodile/\n│   │   ...\n│   └── test/\n│       └── Abomasnow/\n│       └── Electabuzz/\n│       └── Totodile/\n│       ...",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "data_report.html#processed-data",
    "href": "data_report.html#processed-data",
    "title": "Data Report",
    "section": "",
    "text": "Name\nSource\nStorage location\n\n\n\n\nVectorized Pokemon Dataset\nPokemon Stats & Rankings\ndata_acquisition/vectorized_data/all_overall_rankings_vectorized.csv\n\n\nBattle Outcome Dataset\nBattle Simulation Data\ndata_acquisition/vectorized_data/battle_data_numeric.csv\n\n\nImage Training Dataset\nPokemon Image Dataset\ndata_acquisition/image_dataset/final_pokemon_dataset/\n\n\n\n\n\n\n\nDescription: Vectorized version of the Pokemon Stats & Rankings dataset for machine learning applications\nProcessing steps:\n\nRemoval of duplicate entries\nVectorization of categorical features (Pokemon types, moves)\nFeature engineering: type effectiveness calculations, stat ratios, move type diversity\nEncoding of categorical variables using numerical mapping dictionaries\nNormalization of numerical features\nPreparation for model input\n\nVectorization process:\n\nCategorical features converted to numerical representations using mapping dictionaries\nTypes, fast moves, and charged moves encoded using dedicated mapping files:\n\ndata_acquisition/dictionarie/type_to_number.csv\ndata_acquisition/dictionarie/fast_move_to_number.csv\ndata_acquisition/dictionarie/charged_move_to_number.csv\n\nVectorization performed in pokemon_vectorization.ipynb\n\nAccess method: CSV file accessible via pandas DataFrame loading\n\n\n\n\nVectorized feature set with all categorical variables converted to numerical representations\nStandardized numerical ranges for model compatibility\nPreserves all information from the original dataset in machine learning-ready format\n\n\n\n\n\n\nDescription: The battle_data_numeric.csv dataset is already processed and ready for machine learning\nProcessing steps:\n\nCategorical variables (Pokemon types, moves) numerically encoded using reference dictionaries\nFeature pairing to represent both Pokemon in each battle scenario\nBalancing of win/loss outcomes for unbiased model training\nNormalization of numerical features where appropriate\n\nAccess method: Structured CSV with all features in numeric format, directly suitable for ML model training",
    "crumbs": [
      "Data Report"
    ]
  },
  {
    "objectID": "evaluation.html",
    "href": "evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "Evaluation\n\nDo results meet user needs?\nYes – the battle prediction model and image classifier satisfy the requirements for the Pokémon GO Battle Assistant.\n\n\nContinue the project?\nNo – we will not proceed with further development at this time.\n\n\nPlanning of the deployment\n\nPackage the CatBoost battle predictor and the CNN image classifier as REST endpoints.\n\nIntegrate into the existing web/mobile application for real‐time use.\n\n\n\nAdditional data mining iteration (if we were to continue)\n\nExpand the image dataset with more Pokémon from Pokémon GO to improve classification coverage.\n\nIntroduce further feature engineering on battle data to increase accuracy above 0.79.\n\n\n\nEnhance the pre-trained EfficientNetB0 model with:\n\nMore extensive fine-tuning of deeper layers\nMore sophisticated data augmentation techniques\nImplement support for missing Pokémon species to increase coverage\n\n\n\nGovernance and ethical considerations\nNo governance issues or ethical concerns were encountered.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "md-templates/data_report.html",
    "href": "md-templates/data_report.html",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "All information on the data used in the project is compiled in the data report in order to ensure the traceability and reproducibility of the results and to enable a systematic expansion of the database.\nTypically, in the exploratory analysis of the acquired raw data, quality and other issues are identified, which require pre-processing, merging of individual datasets and feature engineering into processed datasets. Therefore, this template provides a separate section for the processed data, which then serves as a starting point for the modelling activities. This needs to be adapted to the specific project requirements.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nQuelle\nStorage location\n\n\n\n\nDataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nDataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails of the data source/provider\nInformation on data procurement: description and possibly references to resources (download scripts, tools, online services, …). Any new team member should be able to acquire the data indepentendently following these instructions.\nLegal aspects of data use, licences, etc.\nData governance aspects: Categorisation of the data based on internal business requirements, e.g. public, business-relevant, personal\nIf applicable: categorisation into dependent (target variable, regressor) and independent (regressor) variables\n…\n\n\n\nThe data catalogue basically represents an extended schema of a relational database.\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nQuelle\nStorage location\n\n\n\n\nProcessed Dataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nProcessed Dataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails and reasons for the processing steps -&gt; Traceability and ensuring reproducibility\nHow can the data be accessed? Description, scripts, tools, …\n…\n\n\n\n\n\n\n\n\n\n\n…"
  },
  {
    "objectID": "md-templates/data_report.html#raw-data",
    "href": "md-templates/data_report.html#raw-data",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "Name\nQuelle\nStorage location\n\n\n\n\nDataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nDataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails of the data source/provider\nInformation on data procurement: description and possibly references to resources (download scripts, tools, online services, …). Any new team member should be able to acquire the data indepentendently following these instructions.\nLegal aspects of data use, licences, etc.\nData governance aspects: Categorisation of the data based on internal business requirements, e.g. public, business-relevant, personal\nIf applicable: categorisation into dependent (target variable, regressor) and independent (regressor) variables\n…\n\n\n\nThe data catalogue basically represents an extended schema of a relational database.\n\n\n\n\n\n\n\n\n\n\nColumn index\nColumn name\nDatatype\nValues (Range, validation rules)\nShort description\n\n\n\n\n1\n\n\n\n\n\n\n2"
  },
  {
    "objectID": "md-templates/data_report.html#processed-data",
    "href": "md-templates/data_report.html#processed-data",
    "title": "Sample Project - Data Report",
    "section": "",
    "text": "Name\nQuelle\nStorage location\n\n\n\n\nProcessed Dataset 1\nName/short description of the data source\nLink and/or short description of the location where the data is stored, e.g. accessible to the team\n\n\nProcessed Dataset 2\n…\n…\n\n\n\n\n\n\n\nDescription of what information the dataset contains\nDetails and reasons for the processing steps -&gt; Traceability and ensuring reproducibility\nHow can the data be accessed? Description, scripts, tools, …\n…\n\n\n\n\n\n\n\n\n\n\n…"
  },
  {
    "objectID": "md-templates/modelling_report.html",
    "href": "md-templates/modelling_report.html",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "The report should summarise the details of the modelling activities, e.g. machine learning experiments.\n\n\n\nAim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed\n\n\n\n\nOverview of the models used and/or implemented and their configurations\n\nDetailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.)\nGraphical representation of the modelling pipeline\nIf applicable: link to the code of the modelling pipeline, version information in code repository, configuration files\nIf possible, links to the artefacts of the executed modelling pipeline (training experiment)\nLink to the literature in which the model/method is described\nHyperparameters\n\n\n\n\nKey figures dependent on the model and modelling objective\n\nRMSD, ROC/Lift-Charts, AUC, Confusion Matrix, Accuracy, Precision, Recall\nCoherence, Perplexity, …\nIf applicable: analyses/plots of (hyper)parameter screenings\n\n\n\n\n\nIf applicable: Results from the application of “explanatory models”\nWere the modelling objectives achieved?\nThe findings resulting from the modelling phase: can the project objective be achieved with the results from the modelling phase?\nHow can the findings be used? Are there any limitations?\n\n\n\n\n\nConclusions of the key findings from the modelling phase\nDiscussion about limitations\nProposal for extensions and further work\nProposal for the deployment of the generated insights/model"
  },
  {
    "objectID": "md-templates/modelling_report.html#initial-situation",
    "href": "md-templates/modelling_report.html#initial-situation",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Aim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed"
  },
  {
    "objectID": "md-templates/modelling_report.html#model-descriptions",
    "href": "md-templates/modelling_report.html#model-descriptions",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Overview of the models used and/or implemented and their configurations\n\nDetailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.)\nGraphical representation of the modelling pipeline\nIf applicable: link to the code of the modelling pipeline, version information in code repository, configuration files\nIf possible, links to the artefacts of the executed modelling pipeline (training experiment)\nLink to the literature in which the model/method is described\nHyperparameters"
  },
  {
    "objectID": "md-templates/modelling_report.html#results",
    "href": "md-templates/modelling_report.html#results",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Key figures dependent on the model and modelling objective\n\nRMSD, ROC/Lift-Charts, AUC, Confusion Matrix, Accuracy, Precision, Recall\nCoherence, Perplexity, …\nIf applicable: analyses/plots of (hyper)parameter screenings"
  },
  {
    "objectID": "md-templates/modelling_report.html#model-interpretation",
    "href": "md-templates/modelling_report.html#model-interpretation",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "If applicable: Results from the application of “explanatory models”\nWere the modelling objectives achieved?\nThe findings resulting from the modelling phase: can the project objective be achieved with the results from the modelling phase?\nHow can the findings be used? Are there any limitations?"
  },
  {
    "objectID": "md-templates/modelling_report.html#conclusions-and-next-steps",
    "href": "md-templates/modelling_report.html#conclusions-and-next-steps",
    "title": "Sample Project - Modelling Report",
    "section": "",
    "text": "Conclusions of the key findings from the modelling phase\nDiscussion about limitations\nProposal for extensions and further work\nProposal for the deployment of the generated insights/model"
  },
  {
    "objectID": "modelling_report.html",
    "href": "modelling_report.html",
    "title": "Modelling Report",
    "section": "",
    "text": "Summarization of details of the modelling activities.\n\n\nOur aim of the modellng is to be able to accurately predict who the winner of a pokemon battle is when given two pokemon. The data set used is the (pokemon_data.csv) Our independant variables are all of the stats for the pokemon (type, moves, attack, defence, etc.), and our dependant variable is the ‘win’ variable. We created several models, including Logistic Regression, Random Forest, and Gradient Boosting. For our final product, we will be using the Gradient Boosting Model.\n\nAim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed\n\n\n\n\nOverview of the models used and/or implemented and their configurations - Detailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.) - Graphical representation of the modelling pipeline - If applicable: link to the code of the modelling pipeline, version information in code repository, configuration files - If possible, links to the artefacts of the executed modelling pipeline (training experiment) - Link to the literature in which the model/method is described - Hyperparameters\n\n\nModel Explanation: The logistic regression model works by predicting the probability of a binary outcome by applying a sigmoid function to a weighted sum of input features.\nApplication: As an initial baseline, logistic regression was trained alongside our ensemble models. While computationally efficient and straightforward to interpret, it plateaued at ~50% accuracy—no better than random guessing—so we discontinued its development early.\nSoftware Library: Python version 3.15.5: pandas, numpy, and sklearn libraries\n\n\n\nModel Explanation: The random forest model works by making predictions by combining the results of many decision trees, each trained on random subsets of the data and features, which improves accuracy and reduces overfitting.\nApplication: After hyperparameter tuning via grid search, the random forest classifier achieved ~69% validation accuracy. Although competitive with gradient boosting’s ~72%, its treatment of categorical Pokémon type features proved slightly less effective, leading us to concentrate further efforts on boosting methods.\nSoftware Library: Python version 3.13.5: os, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.ensemble, sklearn.metrics, sklearn.preprocessing, joblib\n\n\n\nModel Explanation: The gradient boosting model is an ensemble technique that builds decision trees sequentially, where each new tree is trained to correct the errors (residuals) of the previous ensemble. It optimizes a loss function via gradient descent in function space, reducing bias and improving predictive performance.\nApplication: Leveraging iterative feature engineering—such as stat ratio features—the gradient boosting model’s performance climbed to ~75% accuracy. However, feature‐importance analysis revealed underweighting of categorical type attributes, motivating a search for a model with stronger native categorical support.\nSoftware Library: Python version 3.13.5: os, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.ensemble, sklearn.metrics, sklearn.preprocessing, joblib\n\n\n\n\n\nChosen Model\n\nModel Explanation: The CatBoost model is a gradient boosting algorithm designed for handling categorical features natively. It uses ordered boosting and symmetrical trees to reduce overfitting, automatically encodes categorical variables, and often achieves high accuracy with minimal preprocessing.\nApplication: By adopting CatBoost, which natively encodes categorical variables, we immediately saw validation accuracy jump to ~78%. With additional fine-tuning of iterations, learning rate, and tree depth, performance rose to ~79%. Feature importance plots confirmed that Pokémon types were now appropriately prioritized, solidifying CatBoost as our final production model.\nSoftware Library: Python version 3.13.5: os, sys, argparse, subprocess, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.metrics, catboost\n\n\n\n\n\nContext: a 0 in the Label value mean that the right pokemon won and a 1 meaning that the left pokemon won\nAccuracy: 0.7910\nPrecision: 0.7920\nRecall: 0.7791\nF1 Score: 0.7855\nClassification Report:\n\n\n\nLabel\nPrecision\nRecall\nF1-Score\nSupport\n\n\n\n\n0\n0.79\n0.80\n0.80\n2035\n\n\n1\n0.79\n0.78\n0.79\n1965\n\n\naccuracy\n\n\n0.79\n4000\n\n\nmacro avg\n0.79\n0.79\n0.79\n4000\n\n\nweighted avg\n0.79\n0.79\n0.79\n4000\n\n\n\n\n\n\n\n\nModel Pipeline\n\n\n\n\n\n\n\n\nOur final CatBoost model achieved the highest accuracy (~79%) but also provided clear insights into feature importance. Categorical type features—critical for Pokémon effectiveness—are now weighted appropriately, as evidenced by SHAP and importance rankings.\n- Errors predominantly occur in edge‐case matchups with rare type combinations, suggesting further data augmentation could help.\n- The model is robust against overfitting, thanks to CatBoost’s ordered boosting and built-in regularization.\n\n\n\nWe conclude that CatBoost is the optimal choice for our 1v1 battle prediction task, balancing accuracy, interpretability, and categorical feature handling.\n- Limitations: current dataset may underrepresent niche type interactions and extreme stat spreads.\n- Deployment: package the trained CatBoost model implemented into our application - Limitations: current dataset may underrepresent niche type interactions and extreme stat spreads.\n- Deployment: package the trained CatBoost model implemented into our application",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#initial-situation",
    "href": "modelling_report.html#initial-situation",
    "title": "Modelling Report",
    "section": "",
    "text": "Our aim of the modellng is to be able to accurately predict who the winner of a pokemon battle is when given two pokemon. The data set used is the (pokemon_data.csv) Our independant variables are all of the stats for the pokemon (type, moves, attack, defence, etc.), and our dependant variable is the ‘win’ variable. We created several models, including Logistic Regression, Random Forest, and Gradient Boosting. For our final product, we will be using the Gradient Boosting Model.\n\nAim of the modelling - consistent with Data Mining Goals in the project charta\nData set(s) and/or feature set used (references to the data report)\nDescription of the independent variables and (if applicable) the target variable\nType of model used or developed",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#model-descriptions",
    "href": "modelling_report.html#model-descriptions",
    "title": "Modelling Report",
    "section": "",
    "text": "Overview of the models used and/or implemented and their configurations - Detailed description of the model used (e.g. literature references, specification of the software library, exact module, version or other implementation details etc.) - Graphical representation of the modelling pipeline - If applicable: link to the code of the modelling pipeline, version information in code repository, configuration files - If possible, links to the artefacts of the executed modelling pipeline (training experiment) - Link to the literature in which the model/method is described - Hyperparameters\n\n\nModel Explanation: The logistic regression model works by predicting the probability of a binary outcome by applying a sigmoid function to a weighted sum of input features.\nApplication: As an initial baseline, logistic regression was trained alongside our ensemble models. While computationally efficient and straightforward to interpret, it plateaued at ~50% accuracy—no better than random guessing—so we discontinued its development early.\nSoftware Library: Python version 3.15.5: pandas, numpy, and sklearn libraries\n\n\n\nModel Explanation: The random forest model works by making predictions by combining the results of many decision trees, each trained on random subsets of the data and features, which improves accuracy and reduces overfitting.\nApplication: After hyperparameter tuning via grid search, the random forest classifier achieved ~69% validation accuracy. Although competitive with gradient boosting’s ~72%, its treatment of categorical Pokémon type features proved slightly less effective, leading us to concentrate further efforts on boosting methods.\nSoftware Library: Python version 3.13.5: os, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.ensemble, sklearn.metrics, sklearn.preprocessing, joblib\n\n\n\nModel Explanation: The gradient boosting model is an ensemble technique that builds decision trees sequentially, where each new tree is trained to correct the errors (residuals) of the previous ensemble. It optimizes a loss function via gradient descent in function space, reducing bias and improving predictive performance.\nApplication: Leveraging iterative feature engineering—such as stat ratio features—the gradient boosting model’s performance climbed to ~75% accuracy. However, feature‐importance analysis revealed underweighting of categorical type attributes, motivating a search for a model with stronger native categorical support.\nSoftware Library: Python version 3.13.5: os, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.ensemble, sklearn.metrics, sklearn.preprocessing, joblib\n\n\n\n\n\nChosen Model\n\nModel Explanation: The CatBoost model is a gradient boosting algorithm designed for handling categorical features natively. It uses ordered boosting and symmetrical trees to reduce overfitting, automatically encodes categorical variables, and often achieves high accuracy with minimal preprocessing.\nApplication: By adopting CatBoost, which natively encodes categorical variables, we immediately saw validation accuracy jump to ~78%. With additional fine-tuning of iterations, learning rate, and tree depth, performance rose to ~79%. Feature importance plots confirmed that Pokémon types were now appropriately prioritized, solidifying CatBoost as our final production model.\nSoftware Library: Python version 3.13.5: os, sys, argparse, subprocess, pandas, numpy, matplotlib.pyplot, seaborn, sklearn.model_selection, sklearn.metrics, catboost",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#results-of-cat-boost",
    "href": "modelling_report.html#results-of-cat-boost",
    "title": "Modelling Report",
    "section": "",
    "text": "Context: a 0 in the Label value mean that the right pokemon won and a 1 meaning that the left pokemon won\nAccuracy: 0.7910\nPrecision: 0.7920\nRecall: 0.7791\nF1 Score: 0.7855\nClassification Report:\n\n\n\nLabel\nPrecision\nRecall\nF1-Score\nSupport\n\n\n\n\n0\n0.79\n0.80\n0.80\n2035\n\n\n1\n0.79\n0.78\n0.79\n1965\n\n\naccuracy\n\n\n0.79\n4000\n\n\nmacro avg\n0.79\n0.79\n0.79\n4000\n\n\nweighted avg\n0.79\n0.79\n0.79\n4000\n\n\n\n\n\n\n\n\nModel Pipeline",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#model-interpretation",
    "href": "modelling_report.html#model-interpretation",
    "title": "Modelling Report",
    "section": "",
    "text": "Our final CatBoost model achieved the highest accuracy (~79%) but also provided clear insights into feature importance. Categorical type features—critical for Pokémon effectiveness—are now weighted appropriately, as evidenced by SHAP and importance rankings.\n- Errors predominantly occur in edge‐case matchups with rare type combinations, suggesting further data augmentation could help.\n- The model is robust against overfitting, thanks to CatBoost’s ordered boosting and built-in regularization.",
    "crumbs": [
      "Modelling Report"
    ]
  },
  {
    "objectID": "modelling_report.html#conclusions-and-next-steps",
    "href": "modelling_report.html#conclusions-and-next-steps",
    "title": "Modelling Report",
    "section": "",
    "text": "We conclude that CatBoost is the optimal choice for our 1v1 battle prediction task, balancing accuracy, interpretability, and categorical feature handling.\n- Limitations: current dataset may underrepresent niche type interactions and extreme stat spreads.\n- Deployment: package the trained CatBoost model implemented into our application - Limitations: current dataset may underrepresent niche type interactions and extreme stat spreads.\n- Deployment: package the trained CatBoost model implemented into our application",
    "crumbs": [
      "Modelling Report"
    ]
  }
]